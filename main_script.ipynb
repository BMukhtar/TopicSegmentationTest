{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the text data and split it into sentences using a library such as NLTK.\n",
    "\"\"\"\n",
    "import re\n",
    "\n",
    "# Open the VTT file\n",
    "with open('episode_001_large.vtt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = re.sub(r'^WEBVTT\\n\\n', '', text)\n",
    "\n",
    "# Remove the timestamps and extra transcript info using regular expressions\n",
    "text = re.sub(r'\\d{1,2}:\\d{2}.\\d{3} --> \\d{1,2}:\\d{2}.\\d{3}\\n', '', text)  # Remove timestamps\n",
    "text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n",
    "text = re.sub(r'\\n\\n', ' ', text)\n",
    "\n",
    "# Write the modified text to a new file\n",
    "transcript = text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "[\" As part of MIT course 6S099, Artificial General Intelligence,  I've gotten the chance to sit down with Max Tegmark.\",\n 'He is a professor here at MIT.',\n \"He's a physicist, spent a large part of his career  studying the mysteries of our cosmological universe.\",\n \"But he's also studied and delved into the beneficial  possibilities and the existential risks  of artificial intelligence.\",\n 'Amongst many other things, he is the cofounder  of the Future of Life Institute, author of two books,  both of which I highly recommend.']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentences = nltk.sent_tokenize(transcript)\n",
    "sentences[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80745a2d33b24ac185b50c058035d412"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09c7ef5d00e94fc5b4eb47c3bd1b3c5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1441e558b0284004a24a8ca904517bf2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "496c4da8cb54446e8ee4a9e26620257c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f3f2cc60b344e9c987aab547b17db63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/90.9M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e73d30a4809149b7a60163c5fbc12f88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the pre-trained BERT model and tokenizer using a library such as Hugging Face's Transformers.\n",
    "\"\"\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "lib = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(lib)\n",
    "model = AutoModel.from_pretrained(lib)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate BERT embeddings for each sentence by passing them through the pre-trained BERT model.\n",
    "\"\"\"\n",
    "embeddings = []\n",
    "for sentence in sentences:\n",
    "    input_ids = torch.tensor(tokenizer.encode(sentence, add_special_tokens=True)).unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    embeddings.append(last_hidden_states.mean(dim=1).squeeze().detach().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "737"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "384"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akvelon/opt/anaconda3/envs/TopicSegmentation/lib/python3.10/site-packages/sklearn/cluster/_agglomerative.py:983: FutureWarning: Attribute `affinity` was deprecated in version 1.2 and will be removed in 1.4. Use `metric` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use a clustering algorithm, to group the sentences into clusters based on their embeddings.\n",
    "\"\"\"\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "clusterer = AgglomerativeClustering(n_clusters=5, affinity='cosine', linkage='average')\n",
    "clusters = clusterer.fit_predict(embeddings)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "737"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apply heuristics to merge or split the clusters into coherent and meaningful topical segments.\n",
    "\"\"\"\n",
    "segments = []\n",
    "prev_cluster = clusters[0]\n",
    "prev_idx = 0\n",
    "segment_ids = []\n",
    "\n",
    "for i in range(1, len(clusters)):\n",
    "    if clusters[i] != prev_cluster:\n",
    "        segments.append(\" \".join(sentences[prev_idx:i]))\n",
    "        segment_ids.append((prev_idx, i))\n",
    "        prev_cluster = clusters[i]\n",
    "        prev_idx = i\n",
    "\n",
    "segments.append(\" \".join(sentences[prev_idx:]))\n",
    "segment_ids.append((prev_idx, len(sentences)))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "41"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(segments)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " As part of MIT course 6S099, Artificial General Intelligence,  I've gotten the chance to sit down with Max Tegmark. He is a professor here at MIT. He's a physicist, spent a large part of his career  studying the mysteries of our cosmological universe. But he's also studied and delved into the beneficial  possibilities and the existential risks  of artificial intelligence. Amongst many other things, he is the cofounder  of the Future of Life Institute, author of two books,  both of which I highly recommend. First, Our Mathematical Universe. Second is Life 3.0. He's truly an out of the box thinker and a fun personality,  so I really enjoy talking to him. \n",
      "\n",
      "If you'd like to see more of these videos in the future,  please subscribe and also click the little bell icon  to make sure you don't miss any videos. \n",
      "\n",
      "Also, Twitter, LinkedIn, agi.mit.edu  if you wanna watch other lectures  or conversations like this one. Better yet, go read Max's book, Life 3.0. Chapter seven on goals is my favorite. It's really where philosophy and engineering come together  and it opens with a quote by Dostoevsky. The mystery of human existence lies not in just staying alive  but in finding something to live for. Lastly, I believe that every failure rewards us  with an opportunity to learn  and in that sense, I've been very fortunate  to fail in so many new and exciting ways  and this conversation was no different. I've learned about something called  radio frequency interference, RFI, look it up. Apparently, music and conversations  from local radio stations can bleed into the audio  that you're recording in such a way  that it almost completely ruins that audio. It's an exceptionally difficult sound source to remove. So, I've gotten the opportunity to learn  how to avoid RFI in the future during recording sessions. I've also gotten the opportunity to learn  how to use Adobe Audition and iZotope RX 6  to do some noise, some audio repair. Of course, this is an exceptionally difficult noise  to remove. I am an engineer. I'm not an audio engineer. Neither is anybody else in our group  but we did our best. Nevertheless, I thank you for your patience  and I hope you're still able to enjoy this conversation. Do you think there's intelligent life  out there in the universe? Let's open up with an easy question. I have a minority view here actually. When I give public lectures, I often ask for a show of hands  who thinks there's intelligent life out there somewhere else  and almost everyone put their hands up  and when I ask why, they'll be like,  oh, there's so many galaxies out there, there's gotta be. But I'm a numbers nerd, right? So when you look more carefully at it,  it's not so clear at all. When we talk about our universe, first of all,  we don't mean all of space. We actually mean, I don't know,  you can throw me the universe if you want,  it's behind you there. It's, we simply mean the spherical region of space  from which light has a time to reach us so far  during the 14.8 billion year,  13.8 billion years since our Big Bang. There's more space here but this is what we call a universe  because that's all we have access to. So is there intelligent life here  that's gotten to the point of building telescopes  and computers? My guess is no, actually. The probability of it happening on any given planet  is some number we don't know what it is. And what we do know is that the number can't be super high  because there's over a billion Earth like planets  in the Milky Way galaxy alone,  many of which are billions of years older than Earth. And aside from some UFO believers,  there isn't much evidence  that any superduran civilization has come here at all. And so that's the famous Fermi paradox, right? And then if you work the numbers,  what you find is that if you have no clue  what the probability is of getting life on a given planet,  so it could be 10 to the minus 10, 10 to the minus 20,  or 10 to the minus two, or any power of 10  is sort of equally likely  if you wanna be really open minded,  that translates into it being equally likely  that our nearest neighbor is 10 to the 16 meters away,  10 to the 17 meters away, 10 to the 18. By the time you get much less than 10 to the 16 already,  we pretty much know there is nothing else that close. And when you get beyond 10. Because they would have discovered us. Yeah, they would have been discovered as long ago,  or if they're really close,  we would have probably noted some engineering projects  that they're doing. And if it's beyond 10 to the 26 meters,  that's already outside of here. So my guess is actually that we are the only life in here  that's gotten the point of building advanced tech,  which I think is very,  puts a lot of responsibility on our shoulders, not screw up. I think people who take for granted  that it's okay for us to screw up,  have an accidental nuclear war or go extinct somehow  because there's a sort of Star Trek like situation out there  where some other life forms are gonna come and bail us out  and it doesn't matter as much. I think they're leveling us into a false sense of security. I think it's much more prudent to say,  let's be really grateful  for this amazing opportunity we've had  and make the best of it just in case it is down to us. So from a physics perspective,  do you think intelligent life,  so it's unique from a sort of statistical view  of the size of the universe,  but from the basic matter of the universe,  how difficult is it for intelligent life to come about? The kind of advanced tech building life  is implied in your statement that it's really difficult  to create something like a human species. Well, I think what we know is that going from no life  to having life that can do a level of tech,  there's some sort of two going beyond that  than actually settling our whole universe with life. There's some major roadblock there,  which is some great filter as it's sometimes called,  which is tough to get through. It's either that roadblock is either behind us  or in front of us. I'm hoping very much that it's behind us. I'm super excited every time we get a new report from NASA  saying they failed to find any life on Mars. I'm like, yes, awesome. Because that suggests that the hard part,  maybe it was getting the first ribosome  or some very low level kind of stepping stone  so that we're home free. Because if that's true,  then the future is really only limited  by our own imagination. It would be much suckier if it turns out  that this level of life is kind of a dime a dozen,  but maybe there's some other problem. Like as soon as a civilization gets advanced technology,  within a hundred years,  they get into some stupid fight with themselves and poof. That would be a bummer. Yeah, so you've explored the mysteries of the universe,  the cosmological universe, the one that's sitting  between us today. I think you've also begun to explore the other universe,  which is sort of the mystery,  the mysterious universe of the mind of intelligence,  of intelligent life. So is there a common thread between your interest  or the way you think about space and intelligence? Oh yeah, when I was a teenager,  I was already very fascinated by the biggest questions. And I felt that the two biggest mysteries of all in science  were our universe out there and our universe in here. So it's quite natural after having spent  a quarter of a century on my career,  thinking a lot about this one,  that I'm now indulging in the luxury  of doing research on this one. It's just so cool. I feel the time is ripe now  for you trans greatly deepening our understanding of this. Just start exploring this one. Yeah, because I think a lot of people view intelligence  as something mysterious that can only exist  in biological organisms like us,  and therefore dismiss all talk  about artificial general intelligence as science fiction. But from my perspective as a physicist,  I am a blob of quarks and electrons  moving around in a certain pattern  and processing information in certain ways. And this is also a blob of quarks and electrons. I'm not smarter than the water bottle  because I'm made of different kinds of quarks. I'm made of up quarks and down quarks,  exact same kind as this. There's no secret sauce, I think, in me. It's all about the pattern of the information processing. And this means that there's no law of physics  saying that we can't create technology,  which can help us by being incredibly intelligent  and help us crack mysteries that we couldn't. In other words, I think we've really only seen  the tip of the intelligence iceberg so far. Yeah, so the perceptronium. Yeah. So you coined this amazing term. It's a hypothetical state of matter,  sort of thinking from a physics perspective,  what is the kind of matter that can help,  as you're saying, subjective experience emerge,  consciousness emerge. So how do you think about consciousness  from this physics perspective? Very good question. So again, I think many people have underestimated  our ability to make progress on this  by convincing themselves it's hopeless  because somehow we're missing some ingredient that we need. There's some new consciousness particle or whatever. I happen to think that we're not missing anything  and that it's not the interesting thing  about consciousness that gives us  this amazing subjective experience of colors  and sounds and emotions. It's rather something at the higher level  about the patterns of information processing. And that's why I like to think about this idea  of perceptronium. What does it mean for an arbitrary physical system  to be conscious in terms of what its particles are doing  or its information is doing? I don't think, I hate carbon chauvinism,  this attitude you have to be made of carbon atoms  to be smart or conscious. There's something about the information processing  that this kind of matter performs. Yeah, and you can see I have my favorite equations here  describing various fundamental aspects of the world. I feel that I think one day,  maybe someone who's watching this will come up  with the equations that information processing  has to satisfy to be conscious. I'm quite convinced there is big discovery  to be made there because let's face it,  we know that so many things are made up of information. We know that some information processing is conscious  because we are conscious. But we also know that a lot of information processing  is not conscious. Like most of the information processing happening  in your brain right now is not conscious. There are like 10 megabytes per second coming in  even just through your visual system. You're not conscious about your heartbeat regulation  or most things. Even if I just ask you to like read what it says here,  you look at it and then, oh, now you know what it said. But you're not aware of how the computation actually happened. Your consciousness is like the CEO  that got an email at the end with the final answer. So what is it that makes a difference? I think that's both a great science mystery. We're actually studying it a little bit in my lab here  at MIT, but I also think it's just a really urgent question  to answer. For starters, I mean, if you're an emergency room doctor  and you have an unresponsive patient coming in,  wouldn't it be great if in addition to having  a CT scanner, you had a consciousness scanner  that could figure out whether this person  is actually having locked in syndrome  or is actually comatose. And in the future, imagine if we build robots  or the machine that we can have really good conversations  with, which I think is very likely to happen. Wouldn't you want to know if your home helper robot  is actually experiencing anything or just like a zombie,  I mean, would you prefer it? What would you prefer? Would you prefer that it's actually unconscious  so that you don't have to feel guilty about switching it off  or giving boring chores or what would you prefer? Well, certainly we would prefer,  I would prefer the appearance of consciousness. But the question is whether the appearance of consciousness  is different than consciousness itself. And sort of to ask that as a question,  do you think we need to understand what consciousness is,  solve the hard problem of consciousness  in order to build something like an AGI system? No, I don't think that. And I think we will probably be able to build things  even if we don't answer that question. But if we want to make sure that what happens  is a good thing, we better solve it first. So it's a wonderful controversy you're raising there  where you have basically three points of view  about the hard problem. So there are two different points of view. They both conclude that the hard problem of consciousness  is BS. On one hand, you have some people like Daniel Dennett  who say that consciousness is just BS  because consciousness is the same thing as intelligence. There's no difference. So anything which acts conscious is conscious,  just like we are. And then there are also a lot of people,  including many top AI researchers I know,  who say, oh, consciousness is just bullshit  because, of course, machines can never be conscious. They're always going to be zombies. \n",
      "\n",
      "You never have to feel guilty about how you treat them. \n",
      "\n",
      "And then there's a third group of people,  including Giulio Tononi, for example,  and Krzysztof Koch and a number of others. I would put myself also in this middle camp  who say that actually some information processing  is conscious and some is not. So let's find the equation which can be used  to determine which it is. And I think we've just been a little bit lazy,  kind of running away from this problem for a long time. It's been almost taboo to even mention the C word  in a lot of circles because,  but we should stop making excuses. This is a science question and there are ways  we can even test any theory that makes predictions for this. And coming back to this helper robot,  I mean, so you said you'd want your helper robot  to certainly act conscious and treat you,  like have conversations with you and stuff. I think so. But wouldn't you, would you feel,  would you feel a little bit creeped out  if you realized that it was just a glossed up tape recorder,  you know, that was just zombie and was a faking emotion? Would you prefer that it actually had an experience  or would you prefer that it's actually  not experiencing anything so you feel,  you don't have to feel guilty about what you do to it?\n"
     ]
    }
   ],
   "source": [
    "print(' \\n\\n'.join(segments[:5]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: I'm not sure, do you have?\n",
      "Topic 2: Excellent, I didn't know.\n",
      "Topic 3: He said, it was so indescribably beautiful.\n",
      "Topic 4: I speak very bad Russian, I'm only an autodidact,  but I bought a book, Teach Yourself Russian,  read a lot, but it was very difficult.\n",
      "Topic 5: Check it out, some of them are just mind blowing,  really beautiful.\n",
      "Topic 6: You're like, shucks, I'm gonna lose the last five minutes  of experiences since my last cloud backup, dang.\n",
      "Topic 7: Suppose you're going in for a medical procedure  and they're like, you know, for anesthesia,  what we're going to do is we're going to give you  muscle relaxants so you won't be able to move  and you're going to feel excruciating pain  during the whole surgery,  but you won't be able to do anything about it.\n",
      "Topic 8: So the old Holy grail of AI from back to its inception  in the sixties, if that ever happens, of course  I think it's going to be the biggest transition  in the history of life on earth  but it doesn't necessarily have to wait the big impact  until machines are better than us at knitting  that the really big change doesn't come exactly  at the moment they're better than us at everything.\n",
      "Topic 9: If you'd like to see more of these videos in the future,  please subscribe and also click the little bell icon  to make sure you don't miss any videos.\n",
      "Topic 10: I would say alpha go, alpha zero is quite intelligent.\n",
      "Topic 11: You can have a goal to be a good chess player  a good goal player, a good car driver, a good investor  good poet, et cetera.\n",
      "Topic 12: Amongst many other things, he is the cofounder  of the Future of Life Institute, author of two books,  both of which I highly recommend.\n",
      "Topic 13: Although Buddhists say when they watch the water  and that there is some beauty,  that there's some depth and beauty in nature  that they can communicate with.\n",
      "Topic 14: So you could think of the United States Constitution as a way  that people sat down, at the time a bunch of white men,  which is a good example, I should say.\n",
      "Topic 15: So there wasn't that much value in, but more seriously  I think if you ask, not just about being conscious  but maybe having what you would, we might call  an exciting life where you feel passion  and really appreciate the things.\n",
      "Topic 16: But like, can I ask you a question about this?\n",
      "Topic 17: That's, yeah, it feels like in that sense,  experiencing it is a valuable quality.\n",
      "Topic 18: Yes, I speak Russian.\n",
      "Topic 19: I have to.\n",
      "Topic 20: Wow, that's really impressive.\n",
      "Topic 21: So it's quite natural after having spent  a quarter of a century on my career,  thinking a lot about this one,  that I'm now indulging in the luxury  of doing research on this one.\n",
      "Topic 22: And he said like the moment when everything connected  into place in an interview said  it was so indescribably beautiful.\n",
      "Topic 23: You never have to feel guilty about how you treat them.\n",
      "Topic 24: So in terms of, so if you think of a Boston Dynamics  human or robot being sort of with a broom  being pushed around, it starts pushing  on a consciousness question.\n",
      "Topic 25: I don't know, my wife has some calculation,  but my point was, if you play chess,  have you looked at the AlphaZero games?\n",
      "Topic 26: Like if you take, you play chess?\n",
      "Topic 27: That's why I speak so bad.\n",
      "Topic 28: My hunch is that if we ever build a machine where you could  just give it the task, hey, you say, hey, I just realized  I want to travel around the world instead this month.\n",
      "Topic 29: They come up with all these brilliant ideas,  but to communicate with somebody else,  you have to also be able to simulate their own mind.\n",
      "Topic 30: It's okay to boil lobsters because we ask them  if it hurt and they didn't say anything.\n",
      "Topic 31: Slavery was justified by the same kind  of just really weak arguments.\n",
      "Topic 32: Wow.\n",
      "Topic 33: Well, also, another example we can all  relate to of why it doesn't have to be a terrible thing  to be in the presence of people who are even smarter than us  all around is when you and I were both two years old,  I mean, our parents were much more intelligent than us,  right?\n",
      "Topic 34: So if you give me this chance to try to at least  form a question out of this is,  I think it's an interesting idea to think  that we can have intelligent systems,  but we don't know how to describe something to them  and they can't communicate with us.\n",
      "Topic 35: It's hard to, it's hard to really know the difference  between everything seeming like there's consciousness  present, there's intelligence present,  there's affection, passion, love,  and it actually being there.\n",
      "Topic 36: On the other hand, you know, this is really interesting  because I think some people go too far and say,  of course we don't have to have any concerns either  that advanced AI will have those instincts  because we can build anything we want.\n",
      "Topic 37: The actual games, no.\n",
      "Topic 38: That moment when you finally realize the connecting piece  of two conjectures.\n",
      "Topic 39: And I think we've just been a little bit lazy,  kind of running away from this problem for a long time.\n",
      "Topic 40: 1:14:03.440 --> 1:14:05.440\n",
      " The opposite attitude, I think, is to say, 1:14:06.400 --> 1:14:08.800\n",
      " here's this incredible potential, 1:14:08.800 --> 1:14:11.960\n",
      " let's think about what kind of future 1:14:11.960 --> 1:14:14.640\n",
      " we're really, really excited about.\n",
      "Topic 41: It's such a difficult question because, you know,  it's like when you're in a relationship and you say,  well, I love you.\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the centroid sentence for each cluster\n",
    "centroid_sentences = []\n",
    "for start, end in set(segment_ids):\n",
    "    sentences_in_cluster = sentences[start: end]\n",
    "    sentence_embeddings = np.array(embeddings[start: end])\n",
    "    centroid_idx = cdist([s for s in sentence_embeddings], [sentence_embeddings.mean(axis=0)], 'euclidean').argmin()\n",
    "    centroid_sentences.append(sentences_in_cluster[centroid_idx])\n",
    "\n",
    "# Print the topic and its corresponding headline or summary\n",
    "for i, centroid_sentence in enumerate(centroid_sentences):\n",
    "    print(f\"Topic {i+1}: {centroid_sentence}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
